{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - Neural Network Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# grab data from MNIST_data folder\n",
    "# One hot encode each example\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"inputs\"):\n",
    "    x = tf.placeholder(dtype=tf.float32,shape=[None, 784])\n",
    "    y_true = tf.placeholder(dtype=tf.float32,shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Variables\n",
    "with tf.name_scope(\"variables\"):\n",
    "    initializer = tf.variance_scaling_initializer()\n",
    "    w1 = tf.Variable(initializer(shape=[784, 28], dtype=tf.float32))\n",
    "    b1 = tf.Variable(tf.random_uniform(shape=[28],minval=-1, maxval=1))\n",
    "    w2 = tf.Variable(initializer(shape=[28, 10], dtype=tf.float32))\n",
    "    b2 = tf.Variable(tf.random_uniform(shape=[10],minval=-1, maxval=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hidden layer\n",
    "with tf.name_scope(\"hidden_layer\"):\n",
    "    h1 = tf.add(tf.matmul(x, w1), b1)\n",
    "    z1 = tf.nn.relu(h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "with tf.name_scope(\"output\"):\n",
    "    z = tf.add(tf.matmul(z1, w2), b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-Entropy Loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam Optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer =tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "    train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:     0 train loss: 2.654410 eval loss: 2.652552  test_accuracy: 0.113800\n",
      "step:  1500 train loss: 0.489285 eval loss: 0.469836  test_accuracy: 0.888400\n",
      "step:  3000 train loss: 0.354108 eval loss: 0.339654  test_accuracy: 0.909100\n",
      "step:  4500 train loss: 0.309396 eval loss: 0.298879  test_accuracy: 0.917200\n",
      "step:  6000 train loss: 0.284464 eval loss: 0.277251  test_accuracy: 0.921000\n",
      "step:  7500 train loss: 0.266990 eval loss: 0.263274  test_accuracy: 0.924700\n",
      "step:  9000 train loss: 0.253069 eval loss: 0.252451  test_accuracy: 0.926500\n",
      "step: 10500 train loss: 0.240020 eval loss: 0.241830  test_accuracy: 0.930600\n",
      "step: 12000 train loss: 0.228755 eval loss: 0.232136  test_accuracy: 0.933600\n",
      "step: 13500 train loss: 0.218933 eval loss: 0.224562  test_accuracy: 0.935600\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "num_steps = 15000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        \n",
    "        # Get next batch from training dataset\n",
    "        batch_x, batch_y = mnist.train.next_batch(100)\n",
    "        \n",
    "        # Get loss and accuracy every tenth of our training\n",
    "        if i % (num_steps / 10) == 0:\n",
    "            \n",
    "            # Calculate training and evalutation loss\n",
    "            train_loss = sess.run(loss, feed_dict={x:mnist.train.images, y_true:mnist.train.labels})\n",
    "            eval_loss = sess.run(loss, feed_dict={x:mnist.test.images, y_true: mnist.test.labels})\n",
    "            \n",
    "            # operations for calculating accuracy\n",
    "            correct_pred = tf.equal(tf.argmax(z, 1), tf.argmax(y_true, 1))\n",
    "            acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "            \n",
    "            # Calculate accuracy on test set\n",
    "            test_accuracy = sess.run(acc, feed_dict={x: mnist.test.images, y_true:mnist.test.labels})\n",
    "            \n",
    "            # Print metrics of current step\n",
    "            print(\"step: {:5} train loss: {:1f} eval loss: {:1f}  test_accuracy: {:1f}\".format(i, train_loss, eval_loss, test_accuracy))\n",
    "            \n",
    "        # Train model on current batch\n",
    "        sess.run(train, feed_dict={x: batch_x, y_true: batch_y})\n",
    "    \n",
    "    print(\"Finished training\")\n",
    "    \n",
    "    #Save model\n",
    "    saver.save(sess, \"./models/mnist_nn.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/mnist_nn.ckpt\n",
      "0.9386\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./models/mnist_nn.ckpt\")\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(z, 1), tf.argmax(y_true, 1))\n",
    "    \n",
    "    acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    print(sess.run(acc, feed_dict={x: mnist.test.images, y_true:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~94 % accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
